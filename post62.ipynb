{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1y9HH8a7wbuwDgSC7B6so7_EcLVLiZ8WM","timestamp":1663456673785},{"file_id":"https://github.com/hgse-schneider/mmla-gse-colab-notebooks/blob/main/OpenPose.ipynb","timestamp":1663427079762},{"file_id":"https://github.com/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb","timestamp":1646077649693}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# üôÇ **PyFeat**\n","<hr>\n","Original Github repo <a href=\"https://github.com/cosanlab/py-feat\">here</a>. Adapted for <a href=\"https://mmla.gse.harvard.edu/\">ez-mmla</a>, <a href=\"http://lit.gse.harvard.edu/\">Harvard LITLab</a> (Schneider et al.)\n","<br><br>\n","<!-- Ideally, put a GIF or an image here that best portrays the demo or the model. -->\n","<center> <img width=\"600px\" src=\"https://drive.google.com/uc?id=1mv-0KGy1ZWcdbpUrcJTvpSINL-tjyfZa\">\n","</center>\n","<center>The results obtained from PyFeat </center>\n","\n","> Py-Feat provides a comprehensive set of tools and models to easily detect facial expressions (Action Units, emotions, facial landmarks) from images and videos, preprocess & analyze facial expression data, and visualize facial expression data.\n","\n","**Some notes:**\n","* This tool performs best when the face is clear and not too small. \n","* For video detection, the model will be slow if you try to detect for every frame. \n"],"metadata":{"id":"ABHwpUtJ7K3k"}},{"metadata":{"id":"X38L6tanrnrB"},"cell_type":"markdown","source":["## üîß **Setup**\n","<hr>\n","‚è≥ <b>Colab/Colab Pro</b>: 5 minutes\n"]},{"cell_type":"code","source":["#@title #### **Install and import dependencies**\n","#@markdown Install the PyFeat Python library and necessary dependencies.\n","from IPython.display import display, HTML, clear_output\n","\n","completed_actions = []\n","current_action = \"\"\n","\n","def start_step(action):\n","  global current_action\n","  current_action = action\n","  display(HTML(f\"<b style='font-size: 15px'>{action} ‚è≥</b>\"))\n","  display(HTML(\"<hr>\"))\n","\n","def finished():\n","  global current_action, completed_actions\n","  current_action = \"\"\n","  display(HTML(f\"<b style='font-size: 15px; color: green;'>Done ‚úÖ </b>\"))\n","  completed_actions = []\n","\n","def end_step():\n","  global current_action, completed_actions\n","  completed_actions.append(current_action)\n","  current_action = \"\"\n","  clear_output()\n","  for action in completed_actions:\n","    display(HTML(f\"<b style='font-size: 15px'>{action} ‚úÖ </b>\"))\n","    display(HTML(\"<hr>\"))\n","\n","start_step(\"Install py-feat\")\n","!pip install py-feat --q\n","end_step()\n","\n","start_step(\"Install pytube\")\n","!pip install pytube --q\n","end_step()\n","\n","start_step(\"Install imageio\")\n","!pip install imageio==2.4.1 --q\n","end_step()\n","\n","start_step(\"Import necessary libraries\")\n","from IPython.display import display, Javascript,HTML, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode,b64encode\n","from google.colab import files\n","import numpy as np\n","from scipy.io.wavfile import read as wav_read\n","import io\n","from scipy.io.wavfile import write\n","import os\n","from google.colab import drive\n","from pytube import YouTube \n","from moviepy.editor import *\n","import cv2\n","from feat import Detector\n","end_step()\n","\n","start_step(\"Load the PyFeat model\")\n","#@title Load the Model (Detector)\n","from feat import Detector\n","\n","detector = Detector(\n","    face_model=\"retinaface\",\n","    landmark_model=\"mobilefacenet\",\n","    au_model='jaanet',\n","    emotion_model=\"resmasknet\",\n","    facepose_model=\"img2pose\",\n",")\n","detector\n","end_step()\n","\n","finished()"],"metadata":{"id":"4Uv8AXbRvoIG","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üïπ **Demo**\n","<hr>\n","\n","> PyFeat allows for both image and video processing, so choose your input below!"],"metadata":{"id":"vQoRH9mE2ItA"}},{"cell_type":"code","source":["#@title #### **Image/video input**{ run: \"auto\" }\n","#@markdown Choose an option to input the audio or image for the demo and run this cell.\n","import ipywidgets as widgets\n","from google.colab import files\n","from IPython.display import Video, Image\n","from pytube import YouTube \n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode,b64encode\n","import cv2\n","\n","input_file = None\n","image_or_video = \"image\"\n","input = \"Demo picture\" #@param [\"Demo picture\", \"Take a picture\", \"Record video\", \"Upload file\", \"Upload from Google Drive\"]\n","\n","# The function takes in a dictionary of options and their corresponding functions\n","def dropdown_menu(options, on_finished):\n","    global input_file\n","    clear_output()\n","    # Run the associated function\n","    input_file = options[input]()\n","    clear_output()\n","    on_finished(input_file)\n","\n","# This function runs whenever the action user chose finishes.\n","def on_finished(fn):\n","  global image_or_video\n","  if fn:\n","    display(HTML(f\"<hr><b>Below is a preview of the file:</b> <code>{fn}</code><br><br>\"))\n","    if fn[:-4] in ['.mp4', \".mov\", \".avi\"] or image_or_video == \"video\":\n","      image_or_video = \"video\"\n","      display(Video(fn, embed=True, width=400))\n","    else:\n","      image_or_video = \"image\"\n","      display(Image(fn, embed=True, width=400))\n","\n","# Functions corresponding to the actions the user selected!\n","def demo():\n","  global image_or_video\n","  image_or_video = \"image\"\n","\n","  youtube = YouTube('https://www.youtube.com/watch?v=XiRMa9wilVc&t=1s&ab_channel=LiSun')\n","  stream=youtube.streams.get_highest_resolution()\n","  videofile=stream.download()  \n","  vidcap = cv2.VideoCapture(videofile)\n","  success,image = vidcap.read()\n","  file=\"/content/image.jpg\"\n","  cv2.imwrite(file, image)\n","  return file\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  global image_or_video\n","  image_or_video = \"image\"\n","  \n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename\n","\n","def record_video():\n","  global image_or_video\n","  image_or_video = \"video\"\n","\n","  js=Javascript(\"\"\"\n","    async function recordVideo() {\n","      const options = { mimeType: \"video/webm; codecs=vp9\" };\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      const stopCapture = document.createElement(\"button\");\n","      \n","      capture.textContent = \"Start Recording\";\n","      capture.style.background = \"orange\";\n","      capture.style.color = \"white\";\n","\n","      stopCapture.textContent = \"Stop Recording\";\n","      stopCapture.style.background = \"red\";\n","      stopCapture.style.color = \"white\";\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      const recordingVid = document.createElement(\"video\");\n","      video.style.display = 'block';\n","\n","      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n","    \n","      let recorder = new MediaRecorder(stream, options);\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","\n","      video.srcObject = stream;\n","      video.muted = true;\n","\n","      await video.play();\n","\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      await new Promise((resolve) => {\n","        capture.onclick = resolve;\n","      });\n","      recorder.start();\n","      capture.replaceWith(stopCapture);\n","\n","      await new Promise((resolve) => stopCapture.onclick = resolve);\n","      recorder.stop();\n","      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n","      let arrBuff = await recData.data.arrayBuffer();\n","      \n","      // stop the stream and remove the video element\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","\n","      let binaryString = \"\";\n","      let bytes = new Uint8Array(arrBuff);\n","      bytes.forEach((byte) => {\n","        binaryString += String.fromCharCode(byte);\n","      })\n","    return btoa(binaryString);\n","    }\n","  \"\"\")\n","  display(js)\n","  data=eval_js('recordVideo({})')\n","  binary=b64decode(data)\n","  with open(\"/content/recorded_video.mp4\",\"wb\") as video_file:\n","    video_file.write(binary)\n","  return \"/content/recorded_video.mp4\"\n","  \n","def drive_file_chooser(exts):\n","  # This function renders a file chooser which finds all the files of valid extensions\n","  # inside your Google Drive and allows the user to select the file\n","  files = []\n","  FILE_HTML = \"\"\n","\n","  JS = \"\"\"\n","  <style>\n","  .list-item {\n","    background: #eee;\n","    border-radius: 5px;\n","    padding: 5px;\n","    transition: all ease 0.1s;\n","    width: 50%;\n","    margin: 5px;\n","  }\n","  .list-item:hover {\n","    background: #ddd;\n","    transition: all ease 0.1s;\n","  }\n","  </style>\n","  <p> Below are the files obtained from your Google Drive. </p>\n","  <b> Choose a file from the list below. </b>\n","  <hr>\n","  <div> [!!!REPLACE!!!] </div>\n","\n","  <script>\n","    var changestate;\n","    var selection = new Promise(resolve => {\n","      changestate = function(i) {\n","        var el = document.getElementById(i)\n","        el.style.backgroundColor = '#b0ceff';\n","        el.style.fontWeight = \"900\";\n","        resolve(i); \n","      }\n","    });\n","  </script>\n","  \"\"\"\n","  i = 0\n","  for root, directories, filenames in os.walk(\"/content/drive/My Drive\"): \n","    for filename in filenames:\n","      # change the extensions to the type of file we are looking for\n","      if filename.endswith(tuple(exts)):\n","          FILE_HTML += \"\"\"<div id=\"{}\" class=\"list-item\" onclick=\"changestate('{}')\">{}</div>\"\"\".format(i, i, filename)\n","          i += 1\n","          files.append(os.path.join(root,filename))\n","  display(HTML(JS.replace(\"[!!!REPLACE!!!]\", FILE_HTML)))\n","  selection = eval_js(\"selection\")\n","  return files[int(selection)]\n","\n","def google_drive():\n","  from google.colab import drive\n","  display(HTML(\"<i>Please wait while we fetch files from your Google Drive...</i>\"))\n","  drive.mount('/content/drive')\n","  clear_output()\n","  return drive_file_chooser([\"png\", \"jpg\", \"mp4\", \"avi\", \"mov\"])\n","\n","def upload():\n","  try:\n","    uploaded = files.upload()\n","    fn = list(uploaded.keys())[0]\n","    return \"/content/\" + fn\n","  except:\n","    return None\n","\n","dropdown_menu({\n","    \"Demo picture\": demo,\n","    \"Take a picture\": take_photo,\n","    \"Record video\": record_video,\n","    \"Upload file\": upload,\n","    \"Upload from Google Drive\": google_drive,\n","}, on_finished)\n"],"metadata":{"cellView":"form","id":"YvaiuFM1z0HR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #### **Result output** { run: \"auto\" }\n","#@markdown Specify how you want to save your results and run this cell.\n","import time\n","result_output = None\n","output = \"Don't save results\" #@param [\"Don't save results\", \"Download results\", \"Save to Google Drive\"]\n","\n","# The function takes in a dictionary of options and their corresponding functions\n","def dropdown_menu(options, on_finished):\n","    global result_output\n","    clear_output()\n","    # Run the associated function\n","    result_output = options[output]()\n","    clear_output()\n","    on_finished(result_output)\n","\n","def on_finished(input):\n","  clear_output()\n","  global result_output\n","  if input:\n","    result_output = input\n","  if not input:\n","    return\n","  elif input == \"download\":\n","    display(HTML(f\"<hr><b>Results will be downloaded when the demo is finished running.</b><br><br>\"))\n","  else:\n","    display(HTML(f\"<hr><b>Results will be stored to </b><code>{input}</code><b> when the demo is finished running.</b><br><br>\"))\n","\n","def drive_file_chooser():\n","  # This function renders a file chooser which finds all the files of valid extensions\n","  # inside your Google Drive and allows the user to select the file\n","  dirs = []\n","  FILE_HTML = \"\"\n","\n","  JS = \"\"\"\n","  <style>\n","  .list-item {\n","    background: #eee;\n","    border-radius: 5px;\n","    padding: 5px;\n","    transition: all ease 0.1s;\n","    width: 50%;\n","    margin: 5px;\n","  }\n","  .list-item:hover {\n","    background: #ddd;\n","    transition: all ease 0.1s;\n","  }\n","  </style>\n","  <p> Below are the folders obtained from your Google Drive. </p>\n","  <b> Choose a folder to store the model results. </b>\n","  <hr>\n","  <div> [!!!REPLACE!!!] </div>\n","\n","  <script>\n","    var changestate;\n","    var selection = new Promise(resolve => {\n","      changestate = function(i) {\n","        var el = document.getElementById(i)\n","        el.style.backgroundColor = '#b0ceff';\n","        el.style.fontWeight = \"900\";\n","        resolve(i); \n","      }\n","    });\n","  </script>\n","  \"\"\"\n","  i = 0\n","  for root, directories, filenames in os.walk(\"/content/drive/My Drive\"): \n","    for directory in directories:\n","      # change the extensions to the type of file we are looking for\n","        FILE_HTML += \"\"\"<div id=\"{}\" class=\"list-item\" onclick=\"changestate('{}')\">{}</div>\"\"\".format(i, i, directory)\n","        i += 1\n","        dirs.append(os.path.join(root,directory))\n","  display(HTML(JS.replace(\"[!!!REPLACE!!!]\", FILE_HTML)))\n","  selection = eval_js(\"selection\")\n","  return dirs[int(selection)]\n","\n","def google_drive():\n","  from google.colab import drive\n","  display(HTML(\"<i>Please wait while we fetch your Google Drive...</i>\"))\n","  drive.mount('/content/drive')\n","  clear_output()\n","  return drive_file_chooser()\n","\n","def nothing():\n","  return None\n","\n","def download():\n","  return \"download\"\n","\n","dropdown_menu({\n","    \"Don't save results\": nothing,\n","    \"Save to Google Drive\": google_drive,\n","    \"Download results\": download,\n","}, on_finished)\n"],"metadata":{"cellView":"form","id":"N3jbsYW2Voya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #### **Run the demo and save results**\n","#@markdown Run this cell to run the PyFeat model. <br> If you have uploaded a video, change the `skip_frames` parameter to change how the model processes the videos.\n","\n","skip_frames = 30 #@param {type:\"integer\"}\n","\n","from google.colab import files\n","if image_or_video == 'image':\n","  image_prediction = detector.detect_image(input_file)\n","  display(image_prediction)\n","else:\n","  video_prediction = detector.detect_video(input_file, skip_frames=skip_frames)\n","  display(video_prediction)\n","\n","if image_or_video == 'image':\n","  figs = image_prediction.plot_detections(poses=True)[0]\n","else:\n","  axes = video_prediction.emotions.plot()\n","  video_prediction.plot_detections(faceboxes=False, add_titles=False)\n","\n","# Handle output choice\n","if result_output == \"download\":\n","  if image_or_video == 'image':\n","      image_prediction.to_csv('pyfeat_result.csv')\n","      files.download('pyfeat_result.csv')\n","  else:\n","      video_prediction.to_csv('pyfeat_result.csv')\n","      files.download('pyfeat_result.csv')\n","elif result_output:\n","  if image_or_video == 'image':\n","      image_prediction.to_csv(os.path.join(result_output, 'pyfeat_result.csv'))\n","  else:\n","      video_prediction.to_csv(os.path.join(result_output, 'pyfeat_result.csv'))\n","\n","display(HTML(\"<hr>\"))\n","if result_output == \"download\":\n","  display(HTML(f\"<b style='font-size: 15px'>Downloaded results</code> ‚úÖ\"))\n","elif result_output:\n","  display(HTML(f\"<b style='font-size: 15px'>Saved results to </b><code>{result_output}</code> ‚úÖ\"))\n","\n"],"metadata":{"cellView":"form","id":"ksOTyRkw2Yf8"},"execution_count":null,"outputs":[]}]}